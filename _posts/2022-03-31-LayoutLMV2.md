Pre-training of text and layout has proved
effective in a variety of visually-rich document understanding tasks due to its effective model architecture and the advantage
of large-scale unlabeled scanned/digital-born
documents. LayoutLMv2 has introduced new pretraining task for interacting images, text and layout in a single multi-modal framework. 